#!/usr/bin/env python3
"""
JAXA Earth API MCP Server
åœ°çƒè¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã®æ¤œç´¢ãƒ»å–å¾—ãƒ»å‡¦ç†ãƒ»3Dåœ°å½¢ç”Ÿæˆæ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹MCPã‚µãƒ¼ãƒãƒ¼
"""

import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
import traceback

try:
    # æ¨™æº–MCP SDKã®FastMCPã‚’ä½¿ç”¨ï¼ˆå…¬å¼v0.1.5ã‚¹ã‚¿ã‚¤ãƒ«ã«åˆã‚ã›ã‚‹ï¼‰
    from mcp.server.fastmcp import FastMCP, Image
    from jaxa.earth import je
    import requests
    import numpy as np
    import rasterio
    from rasterio.transform import from_bounds
    from PIL import Image as PILImage
    from scipy import ndimage
except ImportError as e:
    print(f"Error importing required libraries: {e}", file=sys.stderr)
    print("Please install dependencies: uv sync", file=sys.stderr)
    sys.exit(1)

# FastMCPã‚µãƒ¼ãƒãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆv0.1.5ã«åˆã‚ã›ã‚‹ï¼‰
mcp = FastMCP("JAXA_Earth_API_Assistant")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
TEMP_DIR = Path("./temp")
TEMP_DIR.mkdir(exist_ok=True)


# ============================================================================
# ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ãƒ„ãƒ¼ãƒ«
# ============================================================================

@mcp.tool()
async def search_collections_id() -> str:
    """
    JAXA Earth APIã§åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è©³ç´°æƒ…å ±ã‚’è¿”ã—ã¾ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆIDã¨ãƒãƒ³ãƒ‰ã‚’é¸æŠã—ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚
    
    è¿”ã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯ã€JAXA Earth APIã‚’é€šã˜ã¦åˆ©ç”¨å¯èƒ½ãªã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒªã‚¹ãƒˆã§ã™ã€‚
    å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¨˜è¿°ã•ã‚Œã¦ã„ã¾ã™ï¼š
    
    id: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸€æ„ã«è­˜åˆ¥ã™ã‚‹ID
    title: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«
    description: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜
    bands: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®IDã€‚è¤‡æ•°ã®IDã¯ã‚«ãƒ³ãƒï¼ˆ,ï¼‰ã§åŒºåˆ‡ã‚‰ã‚Œã¾ã™ã€‚
    keywords: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‚è¦³æ¸¬è¡›æ˜Ÿã®åå‰ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹å®‡å®™æ©Ÿé–¢ã®åå‰ãŒå«ã¾ã‚Œã¾ã™ã€‚
    startDate: ISO8601å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæœŸé–“ã®é–‹å§‹æ—¥æ™‚ã‚’è¡¨ã™æ–‡å­—åˆ—ã€‚ã“ã®æ—¥ä»˜ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
    endDate: ISO8601å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæœŸé–“ã®çµ‚äº†æ—¥æ™‚ã‚’è¡¨ã™æ–‡å­—åˆ—ã€‚"present"ã¨ã„ã†å€¤ã¯ã€ãƒ‡ãƒ¼ã‚¿ãŒã¾ã æ¯æ—¥æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
    å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ‚ã‚ã‚Šã¯"---"ã§ç¤ºã•ã‚Œã¾ã™ã€‚
    bbox: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åœ°ç†çš„ç¯„å›²ï¼ˆãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ï¼‰ã€‚EPSG:4326ã®å ´åˆã€[æœ€å°çµŒåº¦ã€æœ€å°ç·¯åº¦ã€æœ€å¤§çµŒåº¦ã€æœ€å¤§ç·¯åº¦]ã‚’ç¤ºã—ã¾ã™ã€‚EPSG:3995ã¾ãŸã¯EPSG:3031ã®å ´åˆã€[æœ€å°Xã€æœ€å°Yã€æœ€å¤§Xã€æœ€å¤§Y]ã‚’ç¤ºã—ã¾ã™ã€‚
    epsg: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æŠ•å½±æ–¹æ³•ã‚’ç¤ºã™EPSGã‚³ãƒ¼ãƒ‰ã€‚
    
    ä¸Šè¨˜ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«æœ€é©ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆIDã¨ãƒãƒ³ãƒ‰ã‚’é¸æŠã—ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚
    """
    try:
        # JAXA Earth APIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
        JE_TEXT_PATH = "https://data.earth.jaxa.jp/app/mcp/catalog.md"
        response = requests.get(JE_TEXT_PATH)
        je_text = response.text
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
        return je_text
    except Exception as e:
        return f"Error: {str(e)}\n{traceback.format_exc()}"


@mcp.tool()
async def search_collections(keywords: List[str]) -> Dict[str, Any]:
    """
    ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã¨ãƒãƒ³ãƒ‰ã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã—ã¾ã™ã€‚
    
    Args:
        keywords: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["LST", "half-month"]ï¼‰
    
    Returns:
        æ¤œç´¢çµæœã®è¾æ›¸ï¼ˆcollectionsã¨bandsã‚’å«ã‚€ï¼‰
    """
    try:
        collection_list = je.ImageCollectionList()
        collections, bands = collection_list.filter_name(keywords=keywords)
        
        return {
            "collections": collections if isinstance(collections, list) else list(collections),
            "bands": bands if isinstance(bands, list) else list(bands),
            "keywords": keywords
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@mcp.tool()
def list_available_collections() -> Dict[str, Any]:
    """
    åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚
    
    Returns:
        åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒªã‚¹ãƒˆ
    """
    try:
        collection_list = je.ImageCollectionList()
        # ç©ºã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—
        collections, bands = collection_list.filter_name(keywords=[])
        
        return {
            "collections": collections if isinstance(collections, list) else list(collections),
            "bands": bands if isinstance(bands, list) else list(bands),
            "total_count": len(collections) if isinstance(collections, list) else 0
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# ============================================================================
# ç”»åƒå–å¾—ãƒ„ãƒ¼ãƒ«
# ============================================================================

@mcp.tool()
async def show_images(
    collection: str = "JAXA.EORC_ALOS.PRISM_AW3D30.v3.2_global",
    band: str = "DSM",
    dlim: List[str] = ["2021-01-01T00:00:00", "2021-01-01T00:00:00"],
    bbox: List[float] = [135.0, 37.5, 140.0, 42.5],
) -> Any:  # Returns List[Image], but using Any to avoid Pydantic schema error
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«åŸºã¥ã„ã¦JAXA Earth APIã‚’ä½¿ç”¨ã—ã¦è¡›æ˜Ÿç”»åƒã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    
    Args:
        collection: JAXA Earth APIã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ID
        band: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å†…ã®ãƒãƒ³ãƒ‰å
        dlim: é–‹å§‹ã‹ã‚‰çµ‚äº†ã¾ã§ã®æ—¥ä»˜ç¯„å›²åˆ¶é™ã€‚yyyy-mm-ddThh:mm:sså½¢å¼ã®æ—¥ä»˜æ–‡å­—åˆ—
        bbox: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åœ°ç†çš„ç¯„å›²ï¼ˆãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ï¼‰ã€‚EPSG:4326ã®å ´åˆã€[æœ€å°çµŒåº¦ã€æœ€å°ç·¯åº¦ã€æœ€å¤§çµŒåº¦ã€æœ€å¤§ç·¯åº¦]ã‚’ç¤ºã—ã¾ã™
    """
    try:
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã‚µã‚¤ã‚ºã§ppuï¼ˆå˜ä½ã‚ãŸã‚Šã®ãƒ”ã‚¯ã‚»ãƒ«ï¼‰ã‚’è¨­å®š
        image_size = 300  # ç”»åƒã‚µã‚¤ã‚ºã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        ppu = image_size / (bbox[2] - bbox[0])
        
        # ç”»åƒã‚’å–å¾—
        data = je.ImageCollection(collection=collection, ssl_verify=True)\
            .filter_date(dlim=dlim)\
            .filter_resolution(ppu=ppu)\
            .filter_bounds(bbox=bbox)\
            .select(band=band)\
            .get_images()
        
        # ç”»åƒã‚’å‡¦ç†ã—ã¦è¡¨ç¤º
        img_data = je.ImageProcess(data)\
            .show_images(output="buffer")
        
        # PNGãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        output = []
        for png_buffer in img_data.png_buffers:
            output.append(Image(data=png_buffer, format="png"))
        return output
    except Exception as e:
        return [Image(data=f"Error: {str(e)}".encode(), format="text")]


@mcp.tool()
async def get_earth_images(
    collection: str,
    date_range: Optional[List[str]] = None,
    resolution: Optional[float] = None,
    bounds: Optional[List[float]] = None,
    geojson_path: Optional[str] = None,
    band: Optional[str] = None
) -> Dict[str, Any]:
    """
    æ—¥ä»˜ã€è§£åƒåº¦ã€ç¯„å›²ã€ãƒãƒ³ãƒ‰ã‚’æŒ‡å®šã—ã¦åœ°çƒè¦³æ¸¬ç”»åƒã‚’å–å¾—ã—ã¾ã™ã€‚
    
    Args:
        collection: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆä¾‹: "JAXA.EORC_ALOS.PRISM_AW3D30.v3.2_global"ï¼‰
        date_range: æ—¥ä»˜ç¯„å›² [é–‹å§‹æ—¥, çµ‚äº†æ—¥] (ISOå½¢å¼: "YYYY-MM-DDTHH:MM:SS")
        resolution: è§£åƒåº¦ï¼ˆppu: Pixels Per Unitï¼‰
        bounds: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ [min_lon, min_lat, max_lon, max_lat]
        geojson_path: GeoJSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆboundsã‚ˆã‚Šå„ªå…ˆï¼‰
        band: ãƒãƒ³ãƒ‰åï¼ˆä¾‹: "DSM"ï¼‰
    
    Returns:
        å–å¾—ã—ãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±
    """
    try:
        # ImageCollectionã‚’ä½œæˆ
        image_collection = je.ImageCollection(collection)
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
        if date_range:
            image_collection = image_collection.filter_date(date_range)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2021å¹´ã®ãƒ‡ãƒ¼ã‚¿
            image_collection = image_collection.filter_date([
                "2021-01-01T00:00:00",
                "2021-12-31T23:59:59"
            ])
        
        # è§£åƒåº¦ãƒ•ã‚£ãƒ«ã‚¿
        if resolution:
            image_collection = image_collection.filter_resolution(resolution)
        
        # ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿
        if geojson_path and os.path.exists(geojson_path):
            geoj = je.FeatureCollection().read(geojson_path).select([])
            image_collection = image_collection.filter_bounds(geoj=geoj[0] if geoj else None)
        elif bounds:
            image_collection = image_collection.filter_bounds(bbox=bounds)
        
        # ãƒãƒ³ãƒ‰é¸æŠ
        if band:
            image_collection = image_collection.select(band)
        
        # ç”»åƒå–å¾—
        result = image_collection.get_images()
        
        # çµæœæƒ…å ±ã‚’è¿”ã™
        raster = result.raster if hasattr(result, 'raster') else None
        if raster:
            return {
                "success": True,
                "collection": collection,
                "raster_info": {
                    "shape": getattr(raster, 'img', {}).shape if hasattr(raster, 'img') else None,
                    "latlim": getattr(raster, 'latlim', None),
                    "lonlim": getattr(raster, 'lonlim', None)
                }
            }
        else:
            return {
                "success": False,
                "message": "ç”»åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# ============================================================================
# ç”»åƒå‡¦ç†ãƒ„ãƒ¼ãƒ«
# ============================================================================

@mcp.tool()
async def calc_spatial_stats(
    collection: str,
    date_range: Optional[List[str]] = None,
    bounds: Optional[List[float]] = None,
    band: Optional[str] = None
) -> Dict[str, Any]:
    """
    ç©ºé–“çµ±è¨ˆã‚’è¨ˆç®—ã—ã¾ã™ã€‚
    
    Args:
        collection: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
        date_range: æ—¥ä»˜ç¯„å›²
        bounds: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        band: ãƒãƒ³ãƒ‰å
    
    Returns:
        ç©ºé–“çµ±è¨ˆçµæœï¼ˆmean, std, min, max, medianï¼‰
    """
    try:
        # å…¬å¼v0.1.5ã‚¹ã‚¿ã‚¤ãƒ«ã«åˆã‚ã›ã‚‹
        collection_param = collection if collection else "JAXA.EORC_ALOS.PRISM_AW3D30.v3.2_global"
        band_param = band if band else "DSM"
        dlim_param = date_range if date_range else ["2021-01-01T00:00:00", "2021-01-01T00:00:00"]
        bbox_param = bounds if bounds else [135.0, 37.5, 140.0, 42.5]
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã‚µã‚¤ã‚ºã§ppuã‚’è¨­å®š
        image_size = 300
        ppu = image_size / (bbox_param[2] - bbox_param[0])
        
        # ç”»åƒã‚’å–å¾—
        data = je.ImageCollection(collection=collection_param, ssl_verify=True)\
            .filter_date(dlim=dlim_param)\
            .filter_resolution(ppu=ppu)\
            .filter_bounds(bbox=bbox_param)\
            .select(band=band_param)\
            .get_images()
        
        # ç”»åƒã‚’å‡¦ç†
        img_data = je.ImageProcess(data)\
            .calc_spatial_stats()
        
        # çµ±è¨ˆçµæœã‚’è¿”ã™
        return img_data.timeseries if hasattr(img_data, 'timeseries') else {}
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@mcp.tool()
async def show_spatial_stats(
    collection: str = "JAXA.EORC_ALOS.PRISM_AW3D30.v3.2_global",
    band: str = "DSM",
    dlim: List[str] = ["2021-01-01T00:00:00", "2021-01-01T00:00:00"],
    bbox: List[float] = [135.0, 37.5, 140.0, 42.5],
) -> List[Image]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«åŸºã¥ã„ã¦JAXA Earth APIã‚’ä½¿ç”¨ã—ã¦è¡›æ˜Ÿãƒ‡ãƒ¼ã‚¿ã®ç©ºé–“çµ±è¨ˆçµæœç”»åƒã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    
    Args:
        collection: JAXA Earth APIã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ID
        band: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å†…ã®ãƒãƒ³ãƒ‰å
        dlim: é–‹å§‹ã‹ã‚‰çµ‚äº†ã¾ã§ã®æ—¥ä»˜ç¯„å›²åˆ¶é™ã€‚yyyy-mm-ddThh:mm:sså½¢å¼ã®æ—¥ä»˜æ–‡å­—åˆ—
        bbox: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åœ°ç†çš„ç¯„å›²ï¼ˆãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ï¼‰
    """
    try:
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã‚µã‚¤ã‚ºã§ppuã‚’è¨­å®š
        image_size = 300
        ppu = image_size / (bbox[2] - bbox[0])
        
        # ç”»åƒã‚’å–å¾—
        data = je.ImageCollection(collection=collection, ssl_verify=True)\
            .filter_date(dlim=dlim)\
            .filter_resolution(ppu=ppu)\
            .filter_bounds(bbox=bbox)\
            .select(band=band)\
            .get_images()
        
        # ç”»åƒã‚’å‡¦ç†ã—ã¦è¡¨ç¤º
        img_data = je.ImageProcess(data)\
            .calc_spatial_stats()\
            .show_spatial_stats(output="buffer")
        
        # PNGãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        output_images = []
        for png_buffer in img_data.png_buffers_stats:
            output_images.append(Image(data=png_buffer, format="png"))
        
        return output_images
    except Exception as e:
        return [Image(data=f"Error: {str(e)}".encode(), format="text")]


@mcp.tool()
async def calc_temporal_stats(
    collection: str,
    date_range: List[str],
    method: str = "mean",
    bounds: Optional[List[float]] = None,
    band: Optional[str] = None
) -> Dict[str, Any]:
    """
    æ™‚é–“çµ±è¨ˆã‚’è¨ˆç®—ã—ã¾ã™ã€‚
    
    Args:
        collection: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
        date_range: æ—¥ä»˜ç¯„å›²
        method: çµ±è¨ˆæ‰‹æ³• ("mean", "max", "min", "std", "median")
        bounds: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        band: ãƒãƒ³ãƒ‰å
    
    Returns:
        æ™‚é–“çµ±è¨ˆçµæœ
    """
    try:
        image_collection = je.ImageCollection(collection)
        image_collection = image_collection.filter_date(date_range)
        if bounds:
            image_collection = image_collection.filter_bounds(bbox=bounds)
        if band:
            image_collection = image_collection.select(band)
        
        result = image_collection.get_images()
        img_process = je.ImageProcess(result)
        img_process = img_process.calc_temporal_stats(method_query=method)
        
        return {
            "success": True,
            "method": method,
            "temporal_statistics": "è¨ˆç®—å®Œäº†"
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# ============================================================================
# GeoJSONå‡¦ç†ãƒ„ãƒ¼ãƒ«
# ============================================================================

@mcp.tool()
def read_geojson(file_path: str) -> Dict[str, Any]:
    """
    GeoJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    
    Args:
        file_path: GeoJSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    Returns:
        èª­ã¿è¾¼ã‚“ã GeoJSONãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±
    """
    try:
        if not os.path.exists(file_path):
            return {
                "error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}"
            }
        
        feature_collection = je.FeatureCollection().read(file_path)
        features = feature_collection.select([])
        
        return {
            "success": True,
            "file_path": file_path,
            "feature_count": len(features) if isinstance(features, list) else 1
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@mcp.tool()
def select_features(file_path: str, keywords: List[str]) -> Dict[str, Any]:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã‚’é¸æŠã—ã¾ã™ã€‚
    
    Args:
        file_path: GeoJSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        keywords: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        é¸æŠã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã®æƒ…å ±
    """
    try:
        if not os.path.exists(file_path):
            return {
                "error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}"
            }
        
        feature_collection = je.FeatureCollection().read(file_path)
        selected = feature_collection.select(keywords)
        
        return {
            "success": True,
            "keywords": keywords,
            "selected_count": len(selected) if isinstance(selected, list) else 1
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# ============================================================================
# 3Dåœ°å½¢ç”Ÿæˆãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ„ãƒ¼ãƒ«ï¼ˆVRChatå‘ã‘ï¼‰
# ============================================================================

@mcp.tool()
def generate_heightmap(
    collection: str,
    bounds: List[float],
    resolution: float = 20.0,
    date_range: Optional[List[str]] = None,
    output_path: Optional[str] = None
) -> Dict[str, Any]:
    """
    è¡›æ˜Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é«˜åº¦ãƒãƒƒãƒ—ï¼ˆHeightmapï¼‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    
    Args:
        collection: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆæ¨™é«˜ãƒ‡ãƒ¼ã‚¿ç”¨ã€ä¾‹: "JAXA.EORC_ALOS.PRISM_AW3D30.v3.2_global"ï¼‰
        bounds: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ [min_lon, min_lat, max_lon, max_lat]
        resolution: è§£åƒåº¦ï¼ˆppuï¼‰
        date_range: æ—¥ä»˜ç¯„å›²ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€æœªæŒ‡å®šæ™‚ã¯tempãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ï¼‰
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸé«˜åº¦ãƒãƒƒãƒ—ã®æƒ…å ±
    """
    try:
        # æ¨™é«˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        image_collection = je.ImageCollection(collection)
        if date_range:
            image_collection = image_collection.filter_date(date_range)
        image_collection = image_collection.filter_resolution(resolution)
        image_collection = image_collection.filter_bounds(bbox=bounds)
        image_collection = image_collection.select("DSM")  # Digital Surface Model
        
        result = image_collection.get_images()
        raster = result.raster if hasattr(result, 'raster') else None
        
        if not raster or not hasattr(raster, 'img'):
            return {
                "error": "é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            }
        
        # é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã‚’numpyé…åˆ—ã«å¤‰æ›
        height_data = np.array(raster.img)
        
        # æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ã«ï¼‰
        height_min = np.nanmin(height_data)
        height_max = np.nanmax(height_data)
        height_normalized = (height_data - height_min) / (height_max - height_min)
        
        # å‡ºåŠ›ãƒ‘ã‚¹ã‚’æ±ºå®š
        if not output_path:
            output_path = str(TEMP_DIR / "heightmap.png")
        
        # PNGå½¢å¼ã§ä¿å­˜ï¼ˆ16bitã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        height_uint16 = (height_normalized * 65535).astype(np.uint16)
        height_image = Image.fromarray(height_uint16, mode='I;16')
        height_image.save(output_path)
        
        return {
            "success": True,
            "output_path": output_path,
            "shape": height_data.shape,
            "height_range": {
                "min": float(height_min),
                "max": float(height_max)
            },
            "bounds": bounds
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@mcp.tool()
def export_to_blender(
    collection: str,
    bounds: List[float],
    resolution: float = 20.0,
    date_range: Optional[List[str]] = None,
    output_dir: Optional[str] = None
) -> Dict[str, Any]:
    """
    Blenderç”¨ã®é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
    
    Args:
        collection: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
        bounds: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        resolution: è§£åƒåº¦
        date_range: æ—¥ä»˜ç¯„å›²
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±
    """
    try:
        if not output_dir:
            output_dir = str(TEMP_DIR / "blender_export")
        os.makedirs(output_dir, exist_ok=True)
        
        # é«˜åº¦ãƒãƒƒãƒ—ç”Ÿæˆ
        heightmap_result = generate_heightmap(
            collection=collection,
            bounds=bounds,
            resolution=resolution,
            date_range=date_range,
            output_path=os.path.join(output_dir, "heightmap.exr")
        )
        
        if "error" in heightmap_result:
            return heightmap_result
        
        # EXRå½¢å¼ã§é«˜åº¦ãƒãƒƒãƒ—ã‚’ä¿å­˜ï¼ˆ32bitæµ®å‹•å°æ•°ç‚¹ï¼‰
        image_collection = je.ImageCollection(collection)
        if date_range:
            image_collection = image_collection.filter_date(date_range)
        image_collection = image_collection.filter_resolution(resolution)
        image_collection = image_collection.filter_bounds(bbox=bounds)
        image_collection = image_collection.select("DSM")
        
        result = image_collection.get_images()
        raster = result.raster
        height_data = np.array(raster.img).astype(np.float32)
        
        # EXRå½¢å¼ã§ä¿å­˜ï¼ˆrasterioã‚’ä½¿ç”¨ï¼‰
        height_min, height_max = np.nanmin(height_data), np.nanmax(height_data)
        height_normalized = (height_data - height_min) / (height_max - height_min)
        
        exr_path = os.path.join(output_dir, "heightmap.exr")
        # EXRå½¢å¼ã¯PILã§ã¯ç›´æ¥ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãŸã‚ã€PNGå½¢å¼ã§ä¿å­˜
        # å®Ÿéš›ã®EXRå½¢å¼ã¯OpenEXRãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦
        height_uint16 = (height_normalized * 65535).astype(np.uint16)
        height_image = Image.fromarray(height_uint16, mode='I;16')
        height_image.save(exr_path.replace('.exr', '.png'))
        
        # ãƒ†ã‚¯ã‚¹ãƒãƒ£ï¼ˆè¡›æ˜Ÿç”»åƒï¼‰ã‚‚å–å¾—ã—ã¦ä¿å­˜
        texture_path = os.path.join(output_dir, "texture.png")
        # ã“ã“ã§ã¯é«˜åº¦ãƒãƒƒãƒ—ã‚’ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨ã—ã¦ã‚‚ä½¿ç”¨ï¼ˆå®Ÿéš›ã«ã¯åˆ¥ã®ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨å¯èƒ½ï¼‰
        height_image.save(texture_path)
        
        return {
            "success": True,
            "output_dir": output_dir,
            "files": {
                "heightmap": exr_path.replace('.exr', '.png'),
                "texture": texture_path
            },
            "note": "EXRå½¢å¼ã¯PNGå½¢å¼ã§ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚Blenderã§Displace Modifierã‚’ä½¿ç”¨ã™ã‚‹éš›ã¯ã€ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@mcp.tool()
def export_to_unity(
    collection: str,
    bounds: List[float],
    resolution: float = 20.0,
    date_range: Optional[List[str]] = None,
    output_dir: Optional[str] = None
) -> Dict[str, Any]:
    """
    Unityç”¨ã®åœ°å½¢ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
    
    Args:
        collection: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
        bounds: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        resolution: è§£åƒåº¦
        date_range: æ—¥ä»˜ç¯„å›²
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    
    Returns:
        ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±
    """
    try:
        if not output_dir:
            output_dir = str(TEMP_DIR / "unity_export")
        os.makedirs(output_dir, exist_ok=True)
        
        # é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        image_collection = je.ImageCollection(collection)
        if date_range:
            image_collection = image_collection.filter_date(date_range)
        image_collection = image_collection.filter_resolution(resolution)
        image_collection = image_collection.filter_bounds(bbox=bounds)
        image_collection = image_collection.select("DSM")
        
        result = image_collection.get_images()
        raster = result.raster
        height_data = np.array(raster.img).astype(np.float32)
        
        # Unity Terrain Toolç”¨ã®.rawå½¢å¼ã§ä¿å­˜
        # Unityã®Terrainã¯16bitã®é«˜ã•ãƒãƒƒãƒ—ã‚’ä½¿ç”¨
        height_min, height_max = np.nanmin(height_data), np.nanmax(height_data)
        height_normalized = (height_data - height_min) / (height_max - height_min)
        height_uint16 = (height_normalized * 65535).astype(np.uint16)
        
        # .rawå½¢å¼ã§ä¿å­˜ï¼ˆãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã€16bitï¼‰
        raw_path = os.path.join(output_dir, "terrain.raw")
        height_uint16.byteswap(False).tofile(raw_path)
        
        # ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚‚ä¿å­˜
        texture_path = os.path.join(output_dir, "terrain_texture.png")
        height_image = Image.fromarray(height_uint16, mode='I;16')
        height_image.save(texture_path)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆUnityç”¨ã®æƒ…å ±ï¼‰
        metadata = {
            "width": int(height_data.shape[1]),
            "height": int(height_data.shape[0]),
            "depth": 16,  # 16bit
            "height_range": {
                "min": float(height_min),
                "max": float(height_max)
            },
            "bounds": bounds
        }
        
        metadata_path = os.path.join(output_dir, "terrain_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        return {
            "success": True,
            "output_dir": output_dir,
            "files": {
                "terrain_raw": raw_path,
                "texture": texture_path,
                "metadata": metadata_path
            },
            "metadata": metadata,
            "note": "Unityã®Terrain Toolã§.rawãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹éš›ã¯ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@mcp.tool()
def create_vrchat_terrain(
    collection: str,
    bounds: List[float],
    resolution: float = 20.0,
    max_polygons: int = 100000,
    texture_size: int = 2048,
    date_range: Optional[List[str]] = None,
    output_dir: Optional[str] = None
) -> Dict[str, Any]:
    """
    VRChatå‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸåœ°å½¢ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    
    Args:
        collection: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
        bounds: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        resolution: è§£åƒåº¦
        max_polygons: æœ€å¤§ãƒãƒªã‚´ãƒ³æ•°ï¼ˆVRChatåˆ¶ç´„å¯¾å¿œï¼‰
        texture_size: ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚µã‚¤ã‚ºï¼ˆVRChatæ¨å¥¨: 2048ä»¥ä¸‹ï¼‰
        date_range: æ—¥ä»˜ç¯„å›²
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    
    Returns:
        æœ€é©åŒ–ã•ã‚ŒãŸåœ°å½¢ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±
    """
    try:
        if not output_dir:
            output_dir = str(TEMP_DIR / "vrchat_terrain")
        os.makedirs(output_dir, exist_ok=True)
        
        # é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        image_collection = je.ImageCollection(collection)
        if date_range:
            image_collection = image_collection.filter_date(date_range)
        image_collection = image_collection.filter_resolution(resolution)
        image_collection = image_collection.filter_bounds(bbox=bounds)
        image_collection = image_collection.select("DSM")
        
        result = image_collection.get_images()
        raster = result.raster
        height_data = np.array(raster.img).astype(np.float32)
        
        # ãƒãƒªã‚´ãƒ³æ•°åˆ¶ç´„ã«åˆã‚ã›ã¦è§£åƒåº¦ã‚’èª¿æ•´
        current_polygons = height_data.shape[0] * height_data.shape[1] * 2
        if current_polygons > max_polygons:
            scale_factor = np.sqrt(max_polygons / current_polygons)
            new_height = int(height_data.shape[0] * scale_factor)
            new_width = int(height_data.shape[1] * scale_factor)
            height_data = ndimage.zoom(height_data, (new_height / height_data.shape[0], new_width / height_data.shape[1]), order=1)
        
        # ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ãƒªã‚µã‚¤ã‚º
        height_min, height_max = np.nanmin(height_data), np.nanmax(height_data)
        height_normalized = (height_data - height_min) / (height_max - height_min)
        height_uint16 = (height_normalized * 65535).astype(np.uint16)
        
        # ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’ãƒªã‚µã‚¤ã‚º
        texture_image = Image.fromarray(height_uint16, mode='I;16')
        texture_image = texture_image.resize((texture_size, texture_size), Image.Resampling.LANCZOS)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        heightmap_path = os.path.join(output_dir, "vrchat_heightmap.png")
        texture_path = os.path.join(output_dir, "vrchat_texture.png")
        
        texture_image.save(heightmap_path)
        texture_image.save(texture_path)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = {
            "width": int(height_data.shape[1]),
            "height": int(height_data.shape[0]),
            "texture_size": texture_size,
            "estimated_polygons": int(height_data.shape[0] * height_data.shape[1] * 2),
            "height_range": {
                "min": float(height_min),
                "max": float(height_max)
            },
            "bounds": bounds,
            "optimization": {
                "max_polygons": max_polygons,
                "texture_size": texture_size
            }
        }
        
        metadata_path = os.path.join(output_dir, "vrchat_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        return {
            "success": True,
            "output_dir": output_dir,
            "files": {
                "heightmap": heightmap_path,
                "texture": texture_path,
                "metadata": metadata_path
            },
            "metadata": metadata,
            "note": "VRChatã®ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆ100MBï¼‰ã‚’è€ƒæ…®ã—ã¦æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚Blenderã¾ãŸã¯Unityã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@mcp.tool()
def export_texture_maps(
    collection: str,
    bounds: List[float],
    resolution: float = 20.0,
    date_range: Optional[List[str]] = None,
    output_dir: Optional[str] = None
) -> Dict[str, Any]:
    """
    è¡›æ˜Ÿç”»åƒã‚’ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒãƒƒãƒ—ã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ï¼ˆDiffuse, Normalç­‰ï¼‰ã€‚
    
    Args:
        collection: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
        bounds: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        resolution: è§£åƒåº¦
        date_range: æ—¥ä»˜ç¯„å›²
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    
    Returns:
        ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒãƒƒãƒ—ã®æƒ…å ±
    """
    try:
        if not output_dir:
            output_dir = str(TEMP_DIR / "texture_maps")
        os.makedirs(output_dir, exist_ok=True)
        
        # è¡›æ˜Ÿç”»åƒã‚’å–å¾—ï¼ˆè¤‡æ•°ã®ãƒãƒ³ãƒ‰ãŒã‚ã‚‹å ´åˆã¯æœ€åˆã®ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ï¼‰
        image_collection = je.ImageCollection(collection)
        if date_range:
            image_collection = image_collection.filter_date(date_range)
        image_collection = image_collection.filter_resolution(resolution)
        image_collection = image_collection.filter_bounds(bbox=bounds)
        
        # åˆ©ç”¨å¯èƒ½ãªãƒãƒ³ãƒ‰ã‚’å–å¾—
        result = image_collection.get_images()
        raster = result.raster
        image_data = np.array(raster.img)
        
        # Diffuseãƒãƒƒãƒ—ï¼ˆåŸºæœ¬ãƒ†ã‚¯ã‚¹ãƒãƒ£ï¼‰
        if len(image_data.shape) == 2:
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã®å ´åˆã€RGBã«å¤‰æ›
            diffuse_data = np.stack([image_data, image_data, image_data], axis=-1)
        else:
            diffuse_data = image_data
        
        # æ­£è¦åŒ–
        diffuse_normalized = (diffuse_data - np.nanmin(diffuse_data)) / (np.nanmax(diffuse_data) - np.nanmin(diffuse_data))
        diffuse_uint8 = (diffuse_normalized * 255).astype(np.uint8)
        
        diffuse_image = Image.fromarray(diffuse_uint8, mode='RGB')
        diffuse_path = os.path.join(output_dir, "diffuse.png")
        diffuse_image.save(diffuse_path)
        
        # Normalãƒãƒƒãƒ—ï¼ˆç°¡æ˜“ç‰ˆï¼šé«˜åº¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”Ÿæˆï¼‰
        height_data = image_data if len(image_data.shape) == 2 else np.mean(image_data, axis=2)
        normal_map = _generate_normal_map(height_data)
        normal_path = os.path.join(output_dir, "normal.png")
        normal_image = Image.fromarray(normal_map, mode='RGB')
        normal_image.save(normal_path)
        
        return {
            "success": True,
            "output_dir": output_dir,
            "files": {
                "diffuse": diffuse_path,
                "normal": normal_path
            },
            "note": "Normalãƒãƒƒãƒ—ã¯é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç°¡æ˜“çš„ã«ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚ˆã‚Šé«˜å“è³ªãªNormalãƒãƒƒãƒ—ãŒå¿…è¦ãªå ´åˆã¯ã€å°‚ç”¨ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


def _generate_normal_map(height_data: np.ndarray) -> np.ndarray:
    """é«˜åº¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Normalãƒãƒƒãƒ—ã‚’ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    # Sobelãƒ•ã‚£ãƒ«ã‚¿ã§å‹¾é…ã‚’è¨ˆç®—
    sobel_x = ndimage.sobel(height_data, axis=1)
    sobel_y = ndimage.sobel(height_data, axis=0)
    
    # Normalãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—
    normal_x = -sobel_x
    normal_y = -sobel_y
    normal_z = np.ones_like(height_data)
    
    # æ­£è¦åŒ–
    magnitude = np.sqrt(normal_x**2 + normal_y**2 + normal_z**2)
    normal_x /= magnitude
    normal_y /= magnitude
    normal_z /= magnitude
    
    # RGBå½¢å¼ã«å¤‰æ›ï¼ˆ0-255ã®ç¯„å›²ï¼‰
    normal_map = np.stack([
        ((normal_x + 1) * 127.5).astype(np.uint8),
        ((normal_y + 1) * 127.5).astype(np.uint8),
        ((normal_z + 1) * 127.5).astype(np.uint8)
    ], axis=-1)
    
    return normal_map


# ============================================================================
# Plan Mode Tools
# ============================================================================

# Plan storage directory
PLAN_DIR = Path("./_docs/plans")
PLAN_DIR.mkdir(parents=True, exist_ok=True)

@mcp.tool()
def create_plan(
    task_description: str,
    objectives: List[str],
    steps: List[Dict[str, Any]],
    estimated_time: Optional[str] = None
) -> Dict[str, Any]:
    """
    è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®å®Ÿè£…è¨ˆç”»ã‚’ä½œæˆã—ã¾ã™ã€‚
    
    Args:
        task_description: ã‚¿ã‚¹ã‚¯ã®èª¬æ˜
        objectives: ç›®æ¨™ã®ãƒªã‚¹ãƒˆ
        steps: ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒªã‚¹ãƒˆï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã¯è¾æ›¸å½¢å¼ã§ã€description, files, dependencies, riskã‚’å«ã‚€ï¼‰
        estimated_time: æ¨å®šæ™‚é–“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        ä½œæˆã•ã‚ŒãŸè¨ˆç”»ã®æƒ…å ±
    """
    try:
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        plan_id = f"plan_{timestamp}"
        
        plan_data = {
            "id": plan_id,
            "task_description": task_description,
            "objectives": objectives,
            "steps": steps,
            "estimated_time": estimated_time,
            "status": "created",
            "created_at": timestamp,
            "completed_steps": [],
            "current_step": None
        }
        
        # Save plan to file
        plan_file = PLAN_DIR / f"{plan_id}.json"
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan_data, f, ensure_ascii=False, indent=2)
        
        # Generate markdown plan
        markdown_plan = _generate_markdown_plan(plan_data)
        plan_md_file = PLAN_DIR / f"{plan_id}.md"
        with open(plan_md_file, 'w', encoding='utf-8') as f:
            f.write(markdown_plan)
        
        return {
            "plan_id": plan_id,
            "status": "created",
            "plan_file": str(plan_file),
            "markdown_file": str(plan_md_file),
            "total_steps": len(steps),
            "message": f"Plan created successfully with {len(steps)} steps"
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }

@mcp.tool()
def update_plan_status(
    plan_id: str,
    step_index: int,
    status: str,
    notes: Optional[str] = None
) -> Dict[str, Any]:
    """
    è¨ˆç”»ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°ã—ã¾ã™ã€‚
    
    Args:
        plan_id: è¨ˆç”»ID
        step_index: ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0ã‹ã‚‰é–‹å§‹ï¼‰
        status: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆ"pending", "in_progress", "completed", "failed"ï¼‰
        notes: è¿½åŠ ã®ãƒ¡ãƒ¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        æ›´æ–°çµæœ
    """
    try:
        plan_file = PLAN_DIR / f"{plan_id}.json"
        if not plan_file.exists():
            return {"error": f"Plan {plan_id} not found"}
        
        with open(plan_file, 'r', encoding='utf-8') as f:
            plan_data = json.load(f)
        
        if step_index < 0 or step_index >= len(plan_data["steps"]):
            return {"error": f"Invalid step index: {step_index}"}
        
        # Update step status
        plan_data["steps"][step_index]["status"] = status
        if notes:
            plan_data["steps"][step_index]["notes"] = notes
        
        # Update completed steps
        if status == "completed" and step_index not in plan_data["completed_steps"]:
            plan_data["completed_steps"].append(step_index)
        elif status != "completed" and step_index in plan_data["completed_steps"]:
            plan_data["completed_steps"].remove(step_index)
        
        # Update current step
        if status == "in_progress":
            plan_data["current_step"] = step_index
        elif status == "completed" and plan_data["current_step"] == step_index:
            plan_data["current_step"] = None
        
        # Update overall status
        total_steps = len(plan_data["steps"])
        completed_count = len(plan_data["completed_steps"])
        if completed_count == total_steps:
            plan_data["status"] = "completed"
        elif completed_count > 0 or any(s.get("status") == "in_progress" for s in plan_data["steps"]):
            plan_data["status"] = "in_progress"
        
        # Save updated plan
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan_data, f, ensure_ascii=False, indent=2)
        
        # Update markdown file
        markdown_plan = _generate_markdown_plan(plan_data)
        plan_md_file = PLAN_DIR / f"{plan_id}.md"
        with open(plan_md_file, 'w', encoding='utf-8') as f:
            f.write(markdown_plan)
        
        return {
            "plan_id": plan_id,
            "step_index": step_index,
            "status": status,
            "progress": f"{completed_count}/{total_steps} steps completed ({completed_count*100//total_steps}%)",
            "overall_status": plan_data["status"]
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }

@mcp.tool()
def get_plan_status(plan_id: str) -> Dict[str, Any]:
    """
    è¨ˆç”»ã®ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚
    
    Args:
        plan_id: è¨ˆç”»ID
    
    Returns:
        è¨ˆç”»ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±
    """
    try:
        plan_file = PLAN_DIR / f"{plan_id}.json"
        if not plan_file.exists():
            return {"error": f"Plan {plan_id} not found"}
        
        with open(plan_file, 'r', encoding='utf-8') as f:
            plan_data = json.load(f)
        
        total_steps = len(plan_data["steps"])
        completed_count = len(plan_data["completed_steps"])
        
        return {
            "plan_id": plan_id,
            "task_description": plan_data["task_description"],
            "status": plan_data["status"],
            "progress": f"{completed_count}/{total_steps} steps completed",
            "percentage": completed_count * 100 // total_steps if total_steps > 0 else 0,
            "current_step": plan_data["current_step"],
            "steps": [
                {
                    "index": i,
                    "description": step.get("description", ""),
                    "status": step.get("status", "pending"),
                    "files": step.get("files", [])
                }
                for i, step in enumerate(plan_data["steps"])
            ]
        }
    except Exception as e:
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }

def _generate_markdown_plan(plan_data: Dict[str, Any]) -> str:
    """è¨ˆç”»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Markdownå½¢å¼ã®è¨ˆç”»æ›¸ã‚’ç”Ÿæˆ"""
    md = f"# Implementation Plan: {plan_data['task_description']}\n\n"
    md += f"**Plan ID**: `{plan_data['id']}`\n"
    md += f"**Created**: {plan_data['created_at']}\n"
    md += f"**Status**: {plan_data['status']}\n\n"
    
    if plan_data.get('estimated_time'):
        md += f"**Estimated Time**: {plan_data['estimated_time']}\n\n"
    
    md += "## Overview\n\n"
    md += f"{plan_data['task_description']}\n\n"
    
    md += "## Objectives\n\n"
    for obj in plan_data['objectives']:
        md += f"- {obj}\n"
    md += "\n"
    
    md += "## Execution Plan\n\n"
    for i, step in enumerate(plan_data['steps']):
        status_icon = {
            "pending": "â³",
            "in_progress": "ğŸ”„",
            "completed": "âœ…",
            "failed": "âŒ"
        }.get(step.get("status", "pending"), "â³")
        
        md += f"### Step {i+1}: {step.get('description', 'N/A')}\n"
        md += f"**Status**: {status_icon} {step.get('status', 'pending')}\n\n"
        
        if step.get('files'):
            md += f"**Files**: {', '.join(f'`{f}`' for f in step['files'])}\n\n"
        
        if step.get('dependencies'):
            md += f"**Dependencies**: {', '.join(step['dependencies'])}\n\n"
        
        if step.get('risk'):
            md += f"**Risk**: {step['risk']}\n\n"
        
        if step.get('notes'):
            md += f"**Notes**: {step['notes']}\n\n"
        
        md += "---\n\n"
    
    total_steps = len(plan_data['steps'])
    completed_count = len(plan_data['completed_steps'])
    md += f"## Progress\n\n"
    md += f"**Completed**: {completed_count}/{total_steps} steps ({completed_count*100//total_steps if total_steps > 0 else 0}%)\n\n"
    
    return md


# ============================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ============================================================================

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ï¼ˆå…¬å¼v0.1.5ã‚¹ã‚¿ã‚¤ãƒ«ã«åˆã‚ã›ã‚‹ï¼‰
def main():
    mcp.run(transport='stdio')

if __name__ == "__main__":
    main()
